{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import pickle\n",
    "import time\n",
    "from tqdm.notebook import tqdm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('cook_en_test.csv')\n",
    "df_train = pd.read_csv('cook_en_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for t in tqdm(range(len(df_test))):  # Loop over the range of idioms\n",
    "    i = df_test['submission'].iloc[t]  # Access each idiom directly using the loop index\n",
    "\n",
    "    literals = []\n",
    "    for m in range(3):\n",
    "        if len(df_train[(df_train['category'] == 'literal') & (df_train['idiom'] == df_test['idiom'].iloc[t])]) == 0:\n",
    "            text = df_train[(df_train['category'] == 'literal')].sample(1)['submission'].iloc[0]\n",
    "        else:\n",
    "            text = df_train[(df_train['category'] == 'literal') & (df_train['idiom'] == df_test['idiom'].iloc[t])].sample(1)['submission'].iloc[0]\n",
    "        literals.append(text)\n",
    "\n",
    "    figuratives = []\n",
    "    for m in range(3):\n",
    "        if len(df_train[(df_train['category'] == 'figurative') & (df_train['idiom'] == df_test['idiom'].iloc[t])]) == 0:\n",
    "            text = df_train[(df_train['category'] == 'figurative')].sample(1)['submission'].iloc[0]\n",
    "        else:\n",
    "            text = df_train[(df_train['category'] == 'figurative') & (df_train['idiom'] == df_test['idiom'].iloc[t])].sample(1)['submission'].iloc[0]\n",
    "\n",
    "        figuratives.append(text)\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4-0125-preview\",\n",
    "        messages=[\n",
    "    {\"role\": \"system\", \"content\": \n",
    "        \"Your task is to be a language model that speaks English. When responding, follow the given instructions precisely and do not add anything else.\"\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \n",
    "        \"I want you to determine whether the following sentence contains an idiom. If the sentence contains an idiom, write '1'. If it does not, write '0'. Only respond with 0 or 1, do not write anything else. Sentence:\\n\"\n",
    "        + literals[0] + \": 0\\n\" + literals[1] + \": 0\\n\" + literals[2] + \": 0\\n\"\n",
    "        + figuratives[0] + \": 1\\n\" + figuratives[1] + \": 1\\n\" + figuratives[2] + \": 1\\n\"\n",
    "        + i + \": ?\"\n",
    "    }\n",
    "    ]\n",
    "    )\n",
    "    print(completion.choices[0].message.content)\n",
    "\n",
    "    while completion.choices[0].message.content == \"?\" or len(completion.choices[0].message.content) > 1:\n",
    "        completion = client.chat.completions.create(\n",
    "        model=\"gpt-4-0125-preview\",\n",
    "        messages=[\n",
    "    {\"role\": \"system\", \"content\":\n",
    "        \"Your task is to be a language model that speaks English. When responding, follow the given instructions precisely and do not add anything else.\"\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\":\n",
    "        \"I want you to determine whether the following sentence contains an idiom. If the sentence contains an idiom, write '1'. If it does not, write '0'. Only respond with 0 or 1, do not write anything else. Sentence:\\n\"\n",
    "        + literals[0] + \": 0\\n\" + literals[1] + \": 0\\n\" + literals[2] + \": 0\\n\"\n",
    "        + figuratives[0] + \": 1\\n\" + figuratives[1] + \": 1\\n\" + figuratives[2] + \": 1\\n\"\n",
    "        + i + \": ?\"\n",
    "    }\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    results.append(completion)  # Append the result to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(df_test[\"category\"].tolist())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(df_test)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gpt-4-0125-preview_en.pkl', 'wb') as f:\n",
    "      pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = df_test[\"category\"].tolist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([i.choices[0].message.content for i in results])\n",
    "df.to_csv('results_gpt-4-turbo_en.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# read df back"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('results_gpt-4-turbo_en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [i for i, x in enumerate(df[0].tolist()) if x == \"1\\n\"]:\n",
    "    df[0][i] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.iloc[:, 0].tolist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_labels = [int(i) for i in df.iloc[:, 0].tolist()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_labels = [1 if i == \"figurative\" else 0 for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(human_labels, gpt_labels)\n",
    "\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(human_labels, gpt_labels, digits=4)\n",
    "\n",
    "# Write report to a txt file\n",
    "with open('classification_report_gpt-4-0125-preview_en.txt', 'w') as f:\n",
    "    f.write(report)\n",
    "print(report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "gpt_api",
   "language": "python",
   "display_name": "gpt_api"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
